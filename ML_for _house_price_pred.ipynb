{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Detection Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"train.csv\")\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()                 \n",
    "# '''shows the first 5 rows in the data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()  \n",
    "# '''shows description of the data and relevant statistics'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['LONGITUDE'].value_counts()\n",
    "# housing.value_counts()\n",
    "# '''values_count gives values for for the wjole data as well as for 1 particular indices'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['LATITUDE'].describe()\n",
    "# '''It describes 1 particular indices with all the statistics'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline                                  \n",
    "# ''' This command asks the notebook to show the graphs here itself'''\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))          #this command shows the histograph of the data \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train- Test data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):                         #function is defined to split the train and test data\n",
    "    shuffel = np.random.permutation(len(data))          # shuffels the data by random module from np\n",
    "    print (shuffel)\n",
    "    test_set_size = int(len(data) * test_ratio)                 # here determining the size of the test data(lenghth of data * test ratio=20%=0.2)  \n",
    "    test_indices = shuffel[:test_set_size]                      # it says to shuffel the data from 0: size of test data\n",
    "    train_indices = shuffel[test_set_size:]                            # it says to shuffel the data from the size of tewst data : 0\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the problem is due to random module if we run the program again and again the model will train ont the whole train data and no unseen data will be left for the testing due to this the model will overfit itself on this particular data so wee need to fix this keeping the data should be distributed equally to assure all possiblities are there in the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_test(housing, 0.0001)            \n",
    "# '''giving atributes to the function and determiing the function = test_set, train_set'''\n",
    "print (f\"Rows in train set: {len(train_set)}\")\n",
    "print (f\"rows in test set: {len(test_set)}\")                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By sklearn test and train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the whole splitting can be done by sklearn easily as seen under the above thing was for the explanation how it works under the hood\n",
    "also it does the stratified sampling of the data so that some part of the data is left unseen for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, train_size=0.2, random_state=42)\n",
    "print(f\"Rows in train set: {len(train_set)} \\nRows in test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_set, test_set = train_test_split(housing, train_size=0.2, random_state=42)\n",
    "# print(f\"Rows in train set: {len(train_set)} \\nRows in test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit                  # it performs the stratified sampling \n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)      #test size is splitted into 20% and random_state is always 42\n",
    "for train_index, test_index in split.split(housing, housing[\"RESALE\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.describe()\n",
    "strat_train_set[\"RESALE\"].value_counts\n",
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix['TARGET(PRICE_IN_LACS)'].sort_values(ascending=False)\n",
    "# '''This shows the correlation of price with other features and accr. to this price is strongly correlated with sq.ft'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "atributes = ['TARGET(PRICE_IN_LACS)', 'SQUARE_FT', 'BHK_NO.', 'RESALE', 'POSTED_BY']\n",
    "scatter_matrix(housing[atributes], figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\" , x=\"BHK_NO.\", y=\"TARGET(PRICE_IN_LACS)\", alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\" , x=\"SQUARE_FT\", y=\"TARGET(PRICE_IN_LACS)\", alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"PRICESQFT\"] = housing['TARGET(PRICE_IN_LACS)']/housing['SQUARE_FT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['PRICESQFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"MOVE_RESALE\"] = housing['READY_TO_MOVE']/housing['RESALE']\n",
    "housing[\"MOVE_RESALE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix['TARGET(PRICE_IN_LACS)'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"SQUARE_RESALE\"] = housing['SQUARE_FT']/housing['RESALE']\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix['TARGET(PRICE_IN_LACS)'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\" , x=\"SQUARE_FT\", y=\"RESALE\", alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\" , x=\"SQUARE_RESALE\", y=\"TARGET(PRICE_IN_LACS)\", alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"TARGET(PRICE_IN_LACS)\", axis=1)\n",
    "housing_labels = strat_train_set[\"TARGET(PRICE_IN_LACS)\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Missing Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To take care of the missing attributes we have 3 options\n",
    "# 1, Get rid of the missing data poins\n",
    "# 2, get rid of the wjole attribute\n",
    "# 3, set the value to some value (0, mean, median) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = housing.dropna(subset=['RESALE']) # option 1\n",
    "# a.shape\n",
    "'''Till we doesnt writ (,housing) we cannot update the data of housing we jus get a copy ofit in (a)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing.dropna('RESALE', axis=1) # option 2 \n",
    "'''The whole RESALE column will not be there here also the orignal housing data frame will be unchanged same as above'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median = housing['RESALE'].median()   # option 3\n",
    "# housing['RESALE'].fillna(median)\n",
    "'''this changes the missing values and fill the median over there if there are missing values in the train set we also have to edit the test set'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer                            # for filling the missing values as median values \n",
    "imputer = SimpleImputer(strategy='median')\n",
    "# imputer = SimpleImputer(strategy = \"median\")\n",
    "imputer.fit(housing)\n",
    "# imputer.statistics_.shape\n",
    "# imputer.statistics\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_\n",
    "X = imputer.transform(housing)\n",
    "housing_tr = pd.DataFrame(X, columns=housing.columns)                       #using imputer\n",
    "housing_tr.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Priarily three types of objects\n",
    "1. Estimators - It estimates some parameters (eg. imputer) it also has a fit method\n",
    "    it fits the data set and calculates the intrnal parameters.\n",
    "\n",
    "2. Transformers - it takes input and returns outout based in the learnng on fit method fit(). \n",
    "    it also has a convenience func. called fit_transform() which fits and then transforms.\n",
    "\n",
    "3. Predictors - LinearRegression model is and example of predictor. fit() and predict are two common func. \n",
    "    It also gives score func which will evaluate the predictions.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Two types of feature scalling methods:\n",
    "1. Min-Max scalling (normalization)\n",
    "    (value - min) / (max - min)\n",
    "    Sklearn provies class calle MinMaxScaler for this\n",
    "\n",
    "2. Standardization\n",
    "    (value - min) / std \n",
    "    Sklearn provides a class called StandaredScaler for this'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),                          # Creating a pipeline \n",
    "    # .... add as many you want in your pipeline\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr = my_pipeline.fit_transform(housing_tr)\n",
    "housing_num_tr.shape                                                        # Transforming the model along with fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a desiered model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor              # As linear regresson didnt worked we used decision tree\n",
    "from sklearn.ensemble import RandomForestRegressor              # As RandomForest Regressor\n",
    "# model = DecisionTreeRegressor()                               # As DecisionTreeRegressor\n",
    "model = RandomForestRegressor()\n",
    "# model = LinearRegression()\n",
    "model.fit(housing_num_tr, housing_labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "prepared_data = my_pipeline.transform(some_data)\n",
    "model.predict(prepared_data)''''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list (some_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = model.predict(housing_num_tr)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "# mse = mean_squared_error(housing_labels, housing_predictions)   # For decision tree \n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "# rmse = np.sqrt(mse)   # for decision tree '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_rmse\n",
    "# rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using better evaluation technique - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(model, housing_num_tr, housing_labels, scoring = \"neg_mean_squared_error\", cv= 10)\n",
    "# rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_scores(scores):\n",
    "#     print(\"Scores:\", scores)\n",
    "#     print(\"Mean\", scores.mean())\n",
    "#     print(\"Standard deviation:\", scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dumping the model '''\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(model, 'Dragon.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a825f8e8905b8e64233e6384cfa1616d0baa442a3b458fa78e4916d5c671b0d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
